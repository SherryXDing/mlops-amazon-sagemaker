{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90ee35be-13a5-4d18-b99d-5815953b14e2",
   "metadata": {},
   "source": [
    "# Amazon SageMaker Model Monitoring and Clarify Explainability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bcbd0b-92f2-4e04-bcb9-ffe119fdfad6",
   "metadata": {},
   "source": [
    "SageMaker contains several integrated services to monitor models for data and model quality, bias, and explainability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a24d89d-d03a-46b3-98e1-24fb48cec136",
   "metadata": {},
   "source": [
    "In this lab, you will learn how to:\n",
    "  * Capture inference requests, results, and metadata from our pipeline deployed model.\n",
    "  * Schedule a Clarify default monitor to monitor for data drift on a regular schedule.\n",
    "  * Schedule a Clarify model monitor to monitor model performance on a regular schedule.\n",
    "  * Schedule a Clarify bias monitor to monitor predictions for bias drift on a regular schedule.\n",
    "  * Schedule Clarify explainability monitor to monitor predictions for feature attribution drift on a regular schedule."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9962c2-798a-40ba-9ff1-90478ac60ec0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba9df8c-7ae3-48b6-9dee-534298c37399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U sagemaker==2.101.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed43d6e7-b325-4e9b-b8a2-682ee9c8073d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import time\n",
    "import csv\n",
    "import json\n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "default_bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "sagemaker_client = sagemaker_session.sagemaker_client\n",
    "sagemaker_runtime_client = sagemaker_session.sagemaker_runtime_client\n",
    "\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "\n",
    "from sagemaker.clarify import (\n",
    "    BiasConfig,\n",
    "    DataConfig,\n",
    "    ModelConfig,\n",
    "    ModelPredictedLabelConfig,\n",
    "    SHAPConfig,\n",
    ")\n",
    "\n",
    "from sagemaker.model_monitor import (\n",
    "    BiasAnalysisConfig,\n",
    "    CronExpressionGenerator,\n",
    "    DataCaptureConfig,\n",
    "    EndpointInput,\n",
    "    ExplainabilityAnalysisConfig,\n",
    "    ModelBiasMonitor,\n",
    "    ModelExplainabilityMonitor,\n",
    "    DefaultModelMonitor,\n",
    "    ModelQualityMonitor,\n",
    ")\n",
    "\n",
    "from sagemaker.model_monitor.dataset_format import DatasetFormat\n",
    "\n",
    "from sagemaker.s3 import S3Downloader, S3Uploader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8431fa4-be19-4c75-b036-de787bb0e82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"AWS region: {region}\")\n",
    "# A different bucket can be used, but make sure the role for this notebook has\n",
    "# the s3:PutObject permissions. This is the bucket into which the data is captured.\n",
    "print(f\"S3 Bucket: {default_bucket}\")\n",
    "\n",
    "# Endpoint metadata.\n",
    "endpoint_name = \"workshop-project-prod\"\n",
    "endpoint_instance_count = 1\n",
    "endpoint_instance_type = \"ml.m5.large\"\n",
    "print(f\"Endpoint: {endpoint_name}\")\n",
    "\n",
    "prefix = \"sagemaker/DEMO-xgboost-dm-model-monitoring\"\n",
    "s3_key = f\"s3://{default_bucket}/{prefix}\"\n",
    "print(f\"S3 key: {s3_key}\")\n",
    "\n",
    "s3_capture_upload_path = f\"{s3_key}/data_capture\"\n",
    "s3_ground_truth_upload_path = f\"{s3_key}/ground_truth_data/{datetime.now():%Y-%m-%d-%H-%M-%S}\"\n",
    "s3_baseline_results_path = f\"{s3_key}/baselines\"\n",
    "s3_report_path = f\"{s3_key}/reports\"\n",
    "\n",
    "print(f\"Capture path: {s3_capture_upload_path}\")\n",
    "print(f\"Ground truth path: {s3_ground_truth_upload_path}\")\n",
    "print(f\"Baselines path: {s3_baseline_results_path}\")\n",
    "print(f\"Report path: {s3_report_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37712ab-96ff-4e54-b25e-0f1f679aa1b2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Configure data capture and generate synthetic traffic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7a2ae8-2783-4bbb-b902-f27bda0c685d",
   "metadata": {},
   "source": [
    "Data quality monitoring automatically monitors machine learning (ML) models in production and notifies you when data quality issues arise. ML models in production have to make predictions on real-life data that is not carefully curated like most training datasets. If the statistical nature of the data that your model receives while in production drifts away from the nature of the baseline data it was trained on, the model begins to lose accuracy in its predictions. Amazon SageMaker Model Monitor uses rules to detect data drift and alerts you when it happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba425c8-2795-4684-b118-3092a2571829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Predictor Python object for real-time endpoint requests. https://sagemaker.readthedocs.io/en/stable/api/inference/predictors.html\n",
    "predictor = Predictor(endpoint_name=endpoint_name, serializer=CSVSerializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df0a0e9-c655-4e40-a785-5f242613c6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_capture_config = DataCaptureConfig(\n",
    "    enable_capture=True,\n",
    "    sampling_percentage=100,\n",
    "    destination_s3_uri=s3_capture_upload_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a82a002-0921-4c70-a84f-ed43416774ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update endpoint with s3_capture_upload_path.\n",
    "predictor.update_data_capture_config(data_capture_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033abc83-4ba8-452b-8fda-be9f8b7ed85b",
   "metadata": {},
   "source": [
    "### Invoke the deployed model endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a33f51-1cd6-4252-8ba3-69309b7ce687",
   "metadata": {},
   "source": [
    "Now send data to this endpoint to get inferences in real time. \n",
    "\n",
    "With data capture enabled in the previous step, the request and response payload, along with some additional metadata, is saved to the S3 location specified in `DataCaptureConfig`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eedfeb8-8721-4887-9c94-dde6d0b25ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use test set to create a file without headers and labels to mirror data at inference time.\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "test_df.drop(['y_no', 'y_yes'], axis=1).sample(180).to_csv(\"test-samples-no-header.csv\", header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172d7dea-20dd-49f0-8cee-a55b515743dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sending test traffic to the endpoint {}. \\nPlease wait...\".format(endpoint_name))\n",
    "\n",
    "test_sample_df = pd.read_csv(\"test-samples-no-header.csv\")\n",
    "\n",
    "response = predictor.predict(data=test_sample_df.to_numpy())\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4736581-83f3-4b06-8879-b4a4e383e068",
   "metadata": {},
   "source": [
    "### View captured data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829f3bbb-c4f6-4691-a3a5-9a2dcf3ba4ff",
   "metadata": {},
   "source": [
    "List the data capture files stored in Amazon S3. \n",
    "\n",
    "There should be different files from different time periods organized in S3 based on the hour in which the invocation occurred in the format: \n",
    "\n",
    "`s3://{destination-bucket-prefix}/{endpoint-name}/{variant-name}/yyyy/mm/dd/hh/filename.jsonl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c787a9-9286-4e0d-ac55-a90a2724030b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Waiting 30 seconds for captures to show up\", end=\"\")\n",
    "\n",
    "for _ in range(30):\n",
    "    capture_files = sorted(S3Downloader.list(f\"{s3_capture_upload_path}/{endpoint_name}\"))\n",
    "    if capture_files:\n",
    "        break\n",
    "    print(\".\", end=\"\", flush=True)\n",
    "    time.sleep(1)\n",
    "\n",
    "print(\"\\nFound Capture Files:\")\n",
    "print(\"\\n \".join(capture_files[-10:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49645e5-87c5-4f23-8014-7ec66cd79037",
   "metadata": {},
   "source": [
    "Next, view the content of a single capture file, looking at the first few lines in the captured file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3c91e2-6a5b-41ee-8fc1-9f687bb33967",
   "metadata": {},
   "outputs": [],
   "source": [
    "capture_file = S3Downloader.read_file(capture_files[-1]).split(\"\\n\")[-10:-1]\n",
    "print(capture_file[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc467c9-1e05-4831-96c2-813024d5030c",
   "metadata": {},
   "source": [
    "View a single line is present below in a formatted JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f10855-e266-4cc4-a4e3-43ce4829eeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(json.loads(capture_file[-1]), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bab0d7-dbf0-4487-bd69-07c52b60bc00",
   "metadata": {},
   "source": [
    "### Generate synthetic traffic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3b91f0-cad0-4978-a399-09beb1623321",
   "metadata": {},
   "source": [
    "Start a thread to generate synthetic traffic to send continuously to the deployed model endpoint. \n",
    "\n",
    "The `WorkerThread` class will run continuously on the notebook kernel to generate predictions that are captured and sent to S3 until the kernel is restarted or the thread is explicitly terminated. \n",
    "\n",
    "See the cell in the `Cleanup` section to terminate the threads.\n",
    "\n",
    "If there is no traffic, the monitoring jobs are marked as `Failed` since there is no data to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4d6d16-54f8-48d9-885f-406066c4cadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "class WorkerThread(threading.Thread):\n",
    "    def __init__(self, do_run, *args, **kwargs):\n",
    "        super(WorkerThread, self).__init__(*args, **kwargs)\n",
    "        self.__do_run = do_run\n",
    "        self.__terminate_event = threading.Event()\n",
    "\n",
    "    def terminate(self):\n",
    "        self.__terminate_event.set()\n",
    "\n",
    "    def run(self):\n",
    "        while not self.__terminate_event.is_set():\n",
    "            self.__do_run(self.__terminate_event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adeb982-4d2a-4e80-b039-02742636fcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke_endpoint(terminate_event):\n",
    "    with open(\"test-samples-no-header.csv\", \"r\") as f:\n",
    "        i = 0\n",
    "        for row in f:\n",
    "            payload = row.rstrip(\"\\n\")\n",
    "            response = sagemaker_runtime_client.invoke_endpoint(\n",
    "                EndpointName=endpoint_name,\n",
    "                ContentType=\"text/csv\",\n",
    "                Body=payload,\n",
    "                InferenceId=str(i),  # unique ID per row\n",
    "            )\n",
    "            i += 1\n",
    "            response[\"Body\"].read()\n",
    "            time.sleep(1)\n",
    "            if terminate_event.is_set():\n",
    "                break\n",
    "\n",
    "\n",
    "# Keep invoking the endpoint with test data\n",
    "invoke_endpoint_thread = WorkerThread(do_run=invoke_endpoint)\n",
    "invoke_endpoint_thread.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de516b86-2c31-43c7-ab8b-4c841068d2d9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Generate synthetic ground truth data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f8e930-d131-4034-9eae-89a6bc4e2308",
   "metadata": {},
   "source": [
    "Besides data capture, model bias monitoring execution also requires ground truth data.\n",
    "\n",
    "In real use cases, ground truth data should be regularly collected and uploaded to designated S3 location. \n",
    "\n",
    "In this example notebook, below code snippet is used to generate fake ground truth data. The first-party merge container will combine captures and ground truth data, and the merged data will be passed to model bias monitoring job for analysis. Similar to captures, the model bias monitoring execution will fail if there's no data to merge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3ec848-384a-4bed-8191-16aa373a7a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def ground_truth_with_id(inference_id):\n",
    "    # set random seed to get consistent results.\n",
    "    random.seed(inference_id) \n",
    "    rand = random.random()\n",
    "    # format required by the merge container.\n",
    "    return {\n",
    "        \"groundTruthData\": {\n",
    "            # randomly generate positive labels 70% of the time.\n",
    "            \"data\": \"1\" if rand < 0.7 else \"0\",\n",
    "            \"encoding\": \"CSV\",\n",
    "        },\n",
    "        \"eventMetadata\": {\n",
    "            \"eventId\": str(inference_id),\n",
    "        },\n",
    "        \"eventVersion\": \"0\",\n",
    "    }\n",
    "\n",
    "\n",
    "def upload_ground_truth(upload_time):\n",
    "    # 180 are the number of rows in data we're sending for inference.\n",
    "    records = [ground_truth_with_id(i) for i in range(180)]\n",
    "    fake_records = [json.dumps(r) for r in records]\n",
    "    data_to_upload = \"\\n\".join(fake_records)\n",
    "    target_s3_uri = f\"{s3_ground_truth_upload_path}/{upload_time:%Y/%m/%d/%H/%M%S}.jsonl\"\n",
    "    print(f\"Uploading {len(fake_records)} records to\", target_s3_uri)\n",
    "    S3Uploader.upload_string_as_file_body(data_to_upload, target_s3_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f47bd01-ddec-44af-aab2-da0a8eae9d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data for the last hour.\n",
    "upload_ground_truth(datetime.utcnow() - timedelta(hours=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e316390-0166-4faa-9076-40f91097812f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data once a hour.\n",
    "def generate_fake_ground_truth(terminate_event):\n",
    "    upload_ground_truth(datetime.utcnow())\n",
    "    for _ in range(0, 60):\n",
    "        time.sleep(60)\n",
    "        if terminate_event.is_set():\n",
    "            break\n",
    "\n",
    "\n",
    "ground_truth_thread = WorkerThread(do_run=generate_fake_ground_truth)\n",
    "ground_truth_thread.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17a11a4-360f-48d2-a904-0019a55692f6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Monitor data quality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa0ca84-b286-4e0d-8e08-a282b552ec78",
   "metadata": {},
   "source": [
    "Configure `DefaultModelMonitor` for monitoring for data drift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98734c58-07a6-4321-9438-39da26e155dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_quality_monitor = DefaultModelMonitor(\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    volume_size_in_gb=20,\n",
    "    max_runtime_in_seconds=3600,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39591db3-e615-4fb7-8df2-65890a2cdf7d",
   "metadata": {},
   "source": [
    "Start a data quality baseline processing job with `DefaultModelMonitor.suggest_baseline(..)` using the Amazon SageMaker Python SDK. This uses an Amazon SageMaker Model Monitor prebuilt container that generates baseline statistics and suggests baseline constraints for the dataset and writes them to the `output_s3_uri` location that you specify.\n",
    "\n",
    "The baseline calculations of statistics and constraints are needed as a standard against which data drift and other data quality issues can be detected. \n",
    "\n",
    "SageMaker Model Monitor provides a built-in container that provides the ability to suggest the constraints automatically for CSV and flat JSON input. This sagemaker-model-monitor-analyzer container also provides you with a range of model monitoring capabilities, including constraint validation against a baseline, and emitting Amazon CloudWatch metrics. This container is based on Spark and is built with [Deequ \"unit tests for data\"](https://github.com/awslabs/deequ). All column names in your baseline dataset must be compliant with Spark. For column names, use only lowercase characters, and `_` as the only special character.\n",
    "\n",
    "The training dataset that you used to trained the model is usually a good baseline dataset. The training dataset data schema and the inference dataset schema should exactly match (the number and order of the features). Note that the prediction/output columns are assumed to be the first columns in the training dataset. From the training dataset, you can ask SageMaker to suggest a set of baseline constraints and generate descriptive statistics to explore the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694cd456-5d8c-4164-ac0c-571788c1a548",
   "metadata": {},
   "source": [
    "Note: the data quality baseline job can take 5 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8341468d-a74a-4a98-b70e-36353a589fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_quality_baseline_job_name = f\"DataQualityBaselineJob-{datetime.utcnow():%Y-%m-%d-%H%M}\"\n",
    "\n",
    "data_quality_baseline_job = data_quality_monitor.suggest_baseline(\n",
    "    job_name=data_quality_baseline_job_name,\n",
    "    baseline_dataset=\"train-headers.csv\",\n",
    "    dataset_format=DatasetFormat.csv(header=True),\n",
    ")\n",
    "\n",
    "data_quality_baseline_job.wait(logs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0467a9e-67f9-47e0-b8c6-d4dce634b735",
   "metadata": {},
   "source": [
    "Amazon SageMaker Model Monitor prebuilt container computes per column/feature statistics. The statistics are calculated for the baseline dataset and also for the current dataset that is being analyzed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb23e8af-9316-479f-9125-cab3951825e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_data_quality_baseline_job = data_quality_monitor.latest_baselining_job\n",
    "schema_df = pd.json_normalize(latest_data_quality_baseline_job.baseline_statistics().body_dict[\"features\"])\n",
    "schema_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3e1c7e-1f5a-425a-91c4-03484356f09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "constraints_df = pd.json_normalize(latest_data_quality_baseline_job.suggested_constraints().body_dict[\"features\"])\n",
    "constraints_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b0187f-3eb9-4c55-9c7e-7623ef55673c",
   "metadata": {},
   "source": [
    "#### Create a monitoring schedule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b37347d-b15b-491a-bfaa-bba7ea75d195",
   "metadata": {},
   "source": [
    "You can create a data monitoring schedule for the endpoint created earlier. \n",
    "\n",
    "Use the baseline resources (constraints and statistics) to compare against the real-time traffic hourly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9003da3-5e69-42a8-986c-3f2aca9ac1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a data quality monitoring schedule name.\n",
    "data_quality_monitor_schedule_name = (\n",
    "    f\"xgboost-dm-data-monitoring-schedule-{datetime.utcnow():%Y-%m-%d-%H%M}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e4e3a2-39d0-4f12-9f63-91861b222722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an enpointInput\n",
    "endpointInput = EndpointInput(\n",
    "    endpoint_name=predictor.endpoint_name,\n",
    "    # probability_attribute=\"0\",\n",
    "    # probability_threshold_attribute=0.5,\n",
    "    destination=\"/opt/ml/processing/input_data\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e4a57b-ec00-4764-b282-15bcd56a99f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify where to write the data quality monitoring results report to.\n",
    "data_quality_baseline_job_result_uri = f\"{s3_baseline_results_path}/data_quality\"\n",
    "\n",
    "response = data_quality_monitor.create_monitoring_schedule(\n",
    "    monitor_schedule_name=data_quality_monitor_schedule_name,\n",
    "    endpoint_input=endpointInput,\n",
    "    output_s3_uri=data_quality_baseline_job_result_uri,\n",
    "    # ground_truth_input=ground_truth_upload_path,\n",
    "    constraints=latest_data_quality_baseline_job.suggested_constraints(),\n",
    "    # Create the monitoring schedule to execute every hour.    \n",
    "    schedule_cron_expression=CronExpressionGenerator.hourly(),\n",
    "    enable_cloudwatch_metrics=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa8e0ed-ca86-49be-a248-dda50c0b9a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the monitoring schedule\n",
    "# You will see the monitoring schedule in the 'Scheduled' status\n",
    "data_quality_monitor.describe_schedule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fb16f6-b4fe-4317-82e3-e5a36d839e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check default model monitor created.\n",
    "predictor.list_monitors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b547093b-728d-4d7e-8075-33c2979c2b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initially there will be no executions since the first execution happens at the top of the hour\n",
    "# Note that it is common for the execution to launch upto 20 min after the hour.\n",
    "executions = data_quality_monitor.list_executions()\n",
    "executions[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a91aa2-3579-4daa-89c6-dde9e3b4e443",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Monitor model quality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9229fdd6-345a-44da-8978-494f1b094593",
   "metadata": {},
   "source": [
    "Model quality monitoring jobs monitor the performance of a model by comparing the predictions that the model makes with the actual ground truth labels that the model attempts to predict. To do this, model quality monitoring merges data that is captured from real-time inference with actual labels stored in S3, and then compares the predictions with the actual labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167efb77-96c4-458c-8e1c-7e8cbb16721d",
   "metadata": {},
   "source": [
    "### Define `ModelQualityMonitor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b75f1b7-c470-423e-83bd-4deaabbca58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_quality_monitor = ModelQualityMonitor(\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    volume_size_in_gb=20,\n",
    "    max_runtime_in_seconds=1800,\n",
    "    sagemaker_session=sagemaker_session\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df973c1d-536a-462b-910d-8e5cabe57b12",
   "metadata": {},
   "source": [
    "### Run model quality baseline job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d51e52-43d5-4c86-a63d-bc56d564d533",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_threshold = 0.5\n",
    "model_quality_baseline_job_result_uri = f\"{s3_baseline_results_path}/model-quality\"\n",
    "validate_dataset = \"validation_with_predictions.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5b5572-5455-4437-92e7-0ba7bf0e232a",
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = 200  # Need at least 200 samples to compute standard deviations\n",
    "i = 0\n",
    "with open(f\"{validate_dataset}\", \"w\") as baseline_file:\n",
    "    baseline_file.write(\"probability,prediction,label\\n\")  # our header\n",
    "    with open(\"validation.csv\", \"r\") as f:\n",
    "        for row in f:\n",
    "            (label, input_cols) = row.split(\",\", 1)\n",
    "            probability = float(predictor.predict(input_cols))\n",
    "            prediction = \"1\" if probability > prediction_threshold else \"0\"\n",
    "            baseline_file.write(f\"{probability},{prediction},{label}\\n\")\n",
    "            i += 1\n",
    "            if i > limit:\n",
    "                break\n",
    "            print(\".\", end=\"\", flush=True)\n",
    "            time.sleep(0.5)\n",
    "print()\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea7d899-ffde-47fc-9e52-e17ea95dec45",
   "metadata": {},
   "source": [
    "Call the `suggest_baseline` method of the `ModelQualityMonitor` object to run a baseline job.\n",
    "\n",
    "Note: this step can take about 8-10 min."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52436a75-c93e-439d-941e-6c683ef7c48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_quality_baseline_job_name = f\"ModelQualityBaselineJob-{datetime.utcnow():%Y-%m-%d-%H%M}\"\n",
    "\n",
    "model_quality_baseline_job = model_quality_monitor.suggest_baseline(\n",
    "    job_name=model_quality_baseline_job_name,\n",
    "    baseline_dataset=\"validation_with_predictions.csv\", # The S3 location of the validation dataset.\n",
    "    dataset_format=DatasetFormat.csv(header=True),\n",
    "    output_s3_uri = model_quality_baseline_job_result_uri, # The S3 location to store the results.\n",
    "    problem_type=\"BinaryClassification\",\n",
    "    inference_attribute= \"prediction\", # The column in the dataset that contains predictions.\n",
    "    probability_attribute= \"probability\", # The column in the dataset that contains probabilities.\n",
    "    ground_truth_attribute= \"label\" # The column in the dataset that contains ground truth labels.\n",
    ")\n",
    "\n",
    "model_quality_baseline_job.wait(logs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8156d492-fdcf-483b-a418-9c82c643f6bb",
   "metadata": {},
   "source": [
    "View the suggested model quality baseline constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed41270-7e15-42d0-8dc0-7c2c762aee20",
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_model_quality_baseline_job = model_quality_monitor.latest_baselining_job\n",
    "pd.DataFrame(latest_model_quality_baseline_job.suggested_constraints().body_dict[\"binary_classification_constraints\"]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb45df5-11df-42a7-a0d8-28b99ea83f4a",
   "metadata": {},
   "source": [
    "### Schedule continuous model quality monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff101b5-8436-4426-afe3-988d98bfe0dd",
   "metadata": {},
   "source": [
    "You can create a model monitoring schedule for the endpoint created earlier.\n",
    "\n",
    "Use the baseline resources (constraints and statistics) to compare against the real-time traffic hourly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee24a1d-9261-402e-b574-b23eb41356b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_quality_monitor_schedule_name = (\n",
    "    f\"xgboost-dm-model-monitoring-schedule-{datetime.utcnow():%Y-%m-%d-%H%M}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a38ae7-3005-469a-b6a3-dc370f3b9872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an enpointInput\n",
    "endpointInput = EndpointInput(\n",
    "    endpoint_name=predictor.endpoint_name,\n",
    "    probability_attribute=\"0\",\n",
    "    probability_threshold_attribute=0.5,\n",
    "    destination=\"/opt/ml/processing/input_data\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1016da00-e4f6-45ad-81b6-ec332a077cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model_quality_monitor.create_monitoring_schedule(\n",
    "    monitor_schedule_name=model_quality_monitor_schedule_name,\n",
    "    endpoint_input=endpointInput,\n",
    "    output_s3_uri=model_quality_baseline_job_result_uri,\n",
    "    problem_type=\"BinaryClassification\",\n",
    "    ground_truth_input=ground_truth_upload_path,\n",
    "    constraints=latest_model_quality_baseline_job.suggested_constraints(),\n",
    "    schedule_cron_expression=CronExpressionGenerator.hourly(),\n",
    "    # enable_cloudwatch_metrics=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e5f0ef-29e9-4f32-92ee-c82d8280a607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check default model monitor created.\n",
    "predictor.list_monitors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c0e420-388d-41cc-addf-2c72457347f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You will see the monitoring schedule in the 'Scheduled' status.\n",
    "model_quality_monitor.describe_schedule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d19935-e606-43a2-b323-e4d6dd1590ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initially there will be no executions since the first execution happens at the top of the hour\n",
    "# Note that it is common for the execution to luanch upto 20 min after the hour.\n",
    "executions = model_quality_monitor.list_executions()\n",
    "executions[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe98726-fb13-4b88-9baa-e621a57a3323",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Monitor model bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3dc7f2-3cd3-4622-903a-a59ed4ea79df",
   "metadata": {},
   "source": [
    "Model bias monitor can detect bias drift of Machine Learning models in a regular basis. Similar to the other monitoring types, the standard procedure of creating a model bias monitor is first baselining and then monitoring schedule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a93fdb-5bd9-47bc-85cf-7db8450729cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bias_monitor = ModelBiasMonitor(\n",
    "    role=role,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    max_runtime_in_seconds=1800,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976fbf01-ecd4-4654-97aa-a89739a03684",
   "metadata": {},
   "source": [
    "### Create a model bias baseline job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be51844e-6996-4505-9899-4790478c985b",
   "metadata": {},
   "source": [
    "#### Configure `DataConfig`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f8143e-c4ef-4a58-83c6-4ffec76a050e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bias_baseline_job_result_uri = f\"{baseline_results_uri}/model_bias\"\n",
    "\n",
    "model_bias_data_config = DataConfig(\n",
    "    s3_data_input_path=\"train-headers.csv\",\n",
    "    s3_output_path=model_bias_baseline_job_result_uri,\n",
    "    label=\"y_yes\",\n",
    "    headers=train_df.columns.to_list(),\n",
    "    dataset_type=\"text/csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d78b96-8f28-47db-9a7c-9fa229f53651",
   "metadata": {},
   "source": [
    "#### Configure `BiasConfig`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88ac74d-c27b-48c7-8246-a6f195212f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bias_config = BiasConfig(\n",
    "    label_values_or_threshold=[1],\n",
    "    facet_name=\"age\",\n",
    "    facet_values_or_threshold=[100],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31aa3be4-a19a-4ed2-bd6f-1139ac56950c",
   "metadata": {},
   "source": [
    "#### Configure `ModelPredictedLabelConfig`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ede42d-82d5-42bf-a673-18855b86e64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predicted_label_config = ModelPredictedLabelConfig(\n",
    "    probability_threshold=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64926e00-a282-4312-b0f6-16528d544b5b",
   "metadata": {},
   "source": [
    "#### Configure `ModelConfig`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c11716f-f143-47d4-9b52-1afe94912f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = ModelConfig(\n",
    "    model_name=\"Model-gqHK8mt3zYu7\",\n",
    "    instance_count=endpoint_instance_count,\n",
    "    instance_type=endpoint_instance_type,\n",
    "    content_type=\"text/csv\",\n",
    "    accept_type=\"text/csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b33242-d0dd-4b30-bd1b-c9ff4df5c95f",
   "metadata": {},
   "source": [
    "### Run model bias baseline job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213e00ad-65a8-4652-bcc4-9f91880bc907",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bias_baseline_job = model_bias_monitor.suggest_baseline(\n",
    "    model_config=model_config,\n",
    "    data_config=model_bias_data_config,\n",
    "    bias_config=model_bias_config,\n",
    "    model_predicted_label_config=model_predicted_label_config,\n",
    ")\n",
    "\n",
    "model_bias_baseline_job.wait(logs=False)\n",
    "\n",
    "print(f\"ModelBiasMonitor baselining job: {model_bias_monitor.latest_baselining_job_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ac8328-e960-41aa-8a16-895bb32ce4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bias_constraints = model_bias_monitor.suggested_constraints()\n",
    "\n",
    "print(f\"ModelBiasMonitor suggested constraints: {model_bias_constraints.file_s3_uri}\")\n",
    "\n",
    "print(S3Downloader.read_file(model_bias_constraints.file_s3_uri))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbc8cb4-c4bc-4448-87fe-84e1e75b310f",
   "metadata": {},
   "source": [
    "### Schedule continuous model bias monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881fdb65-84d0-466d-887a-fead41be0cbc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8679696f-566f-440c-b67c-906d42411141",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bias_analysis_config = None\n",
    "if not model_bias_monitor.latest_baselining_job:\n",
    "    model_bias_analysis_config = BiasAnalysisConfig(\n",
    "        model_bias_config,\n",
    "        headers=all_headers,\n",
    "        label=label_header,\n",
    "    )\n",
    "\n",
    "model_bias_monitor.create_monitoring_schedule(\n",
    "    analysis_config=model_bias_analysis_config,\n",
    "    output_s3_uri=s3_report_path,\n",
    "    endpoint_input=EndpointInput(\n",
    "        endpoint_name=endpoint_name,\n",
    "        destination=\"/opt/ml/processing/input/endpoint\",\n",
    "        start_time_offset=\"-PT1H\",\n",
    "        end_time_offset=\"-PT0H\",\n",
    "        probability_threshold_attribute=0.5,\n",
    "    ),\n",
    "    ground_truth_input=ground_truth_upload_path,\n",
    "    schedule_cron_expression=schedule_expression,\n",
    ")\n",
    "print(f\"Model bias monitoring schedule: {model_bias_monitor.monitoring_schedule_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e34768-eaf2-4e35-a132-526cd8dee248",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Monitor feature attribution drift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7be6421-e1d6-4302-9841-86253b538a0b",
   "metadata": {},
   "source": [
    "### Define `ModelExplainabilityMonitor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b69ea6-33c5-4801-b766-6e325f38c771",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_explainability_monitor = ModelExplainabilityMonitor(\n",
    "    role=role,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    max_runtime_in_seconds=1800,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ec1e11-6724-4cc5-825f-18cd92501fce",
   "metadata": {},
   "source": [
    "### Run explainability baseline job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad71e9b-2d44-49c5-9dfc-1cedbdab65e0",
   "metadata": {},
   "source": [
    "#### Define data config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a151c4da-2a25-4b87-ae36-9c0837f5b040",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_explainability_baseline_job_result_uri = f\"{baseline_results_path}/model-explainability\"\n",
    "\n",
    "model_explainability_data_config = DataConfig(\n",
    "    s3_data_input_path=\"train-headers.csv\",\n",
    "    s3_output_path=model_explainability_baseline_job_result_uri,\n",
    "    label=\"y_yes\",\n",
    "    headers=train_df.columns.to_list(),\n",
    "    dataset_type=\"text/csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a5c98a-bbaa-4f13-9af5-f327a93b0b92",
   "metadata": {},
   "source": [
    "#### Define Clarify SHAP feature attributions config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0f2a49-dfbf-48fa-aef2-4b3dca80e04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here use the mean value of train dataset as SHAP baseline\n",
    "shap_baseline = [list(train_df.mean())]\n",
    "\n",
    "shap_config = SHAPConfig(\n",
    "    baseline=shap_baseline,\n",
    "    num_samples=100,\n",
    "    agg_method=\"mean_abs\",\n",
    "    save_local_shap_values=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474159d9-60bc-4ce1-84c6-5cafd9528534",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = ModelConfig(\n",
    "    model_name=\"Model-gqHK8mt3zYu7\",\n",
    "    instance_count=endpoint_instance_count,\n",
    "    instance_type=endpoint_instance_type,\n",
    "    content_type=\"text/csv\",\n",
    "    accept_type=\"text/csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76263cf7-fa0a-47c6-9ad1-c59ec1a94512",
   "metadata": {},
   "source": [
    "#### Run baseline job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28440701-45d8-46c8-a445-7156321b158e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_quality_baseline_job_name = f\"ModelExplainabilityBaselineJob-{datetime.utcnow():%Y-%m-%d-%H%M}\"\n",
    "\n",
    "model_explainability_baseline_job = model_explainability_monitor.suggest_baseline(\n",
    "    job_name=model_quality_baseline_job_name,\n",
    "    data_config=model_explainability_data_config,\n",
    "    model_config=model_config,\n",
    "    explainability_config=shap_config,\n",
    ")\n",
    "\n",
    "model_explainability_baseline_job.wait(logs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf3e246-110c-44bf-b975-bdd50f79fdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_explainability_constraints = model_explainability_monitor.suggested_constraints()\n",
    "\n",
    "print(f\"ModelExplainabilityMonitor suggested constraints: {model_explainability_constraints.file_s3_uri}\")\n",
    "print(S3Downloader.read_file(model_explainability_constraints.file_s3_uri))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58046c90-679a-4b39-86b8-a1fd593dc952",
   "metadata": {},
   "source": [
    "#### Schedule model explainability monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631045c6-e2f2-4356-9a68-c160d87b41e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model_explainability_monitor.create_monitoring_schedule(\n",
    "    output_s3_uri=f\"{s3_report_path}/model-explainability\",\n",
    "    endpoint_input=endpoint_name,\n",
    "    schedule_cron_expression=CronExpressionGenerator.hourly(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31dc477f-ff73-48d4-b3be-9037e541465c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check default model monitor created.\n",
    "predictor.list_monitors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0722d0f3-b7cf-4523-bc1d-346edf0528ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the monitoring schedule\n",
    "# You will see the monitoring schedule in the 'Scheduled' status\n",
    "model_explainability_monitor.describe_schedule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72309e7-204b-4d54-a604-6959b39f1b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initially there will be no executions since the first execution happens at the top of the hour\n",
    "# Note that it is common for the execution to luanch upto 20 min after the hour.\n",
    "executions = model_explainability_monitor.list_executions()\n",
    "executions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15753cfa-0311-45ea-8c49-c458f4492eea",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfc1417-ba78-4eb1-9cb5-89e1e59459ea",
   "metadata": {},
   "source": [
    "First, stop the worker threads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea88713-fa42-4c16-87e6-3f579a5aade2",
   "metadata": {},
   "outputs": [],
   "source": [
    "invoke_endpoint_thread.terminate()\n",
    "ground_truth_thread.terminate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68ad424-8a74-4604-be1d-7ef40e85729c",
   "metadata": {},
   "source": [
    "Stop all monitors scheduled to the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de94811e-7294-47c3-94b0-bdafe99e2f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_monitors = predictor.list_monitors()\n",
    "\n",
    "for monitor in model_monitors:\n",
    "    monitor.stop_monitoring_schedule()\n",
    "    monitor.delete_monitoring_schedule()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75242fc7-df70-47fa-b755-1640b266e5d0",
   "metadata": {},
   "source": [
    "Finally, delete the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04634aba-45e4-484b-af5f-cb3854e5dff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()\n",
    "predictor.delete_model()"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
